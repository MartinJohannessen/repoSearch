{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "repoSearch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinJohannessen/repoSearch/blob/main/repoSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnrqYfpsHNYH"
      },
      "source": [
        "Haystack is a open source framework that lets you scale open source QA transformer models to millions of documents using an open source document store, and everything is open source. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eljbikboabpY"
      },
      "source": [
        "!pip install git+https://github.com/deepset-ai/haystack.git\n",
        "#!pip install urllib3==1.25.3\n",
        "!pip install grpcio==1.32.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJZIXFZCHCKf"
      },
      "source": [
        "%%capture\n",
        "#capture on the first line makes the output smaller.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from haystack.preprocessor import PreProcessor\n",
        "from haystack.reader.farm import FARMReader\n",
        "from haystack.reader.transformers import TransformersReader\n",
        "from haystack.pipeline import ExtractiveQAPipeline\n",
        "from haystack.retriever.dense import DensePassageRetriever"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA9KS92HaSoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303707f9-7f6a-4e09-96e6-7ed6478cc9d3"
      },
      "source": [
        "# Make sure you have a GPU running, if not, go to runtime/change runtime type\n",
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgT4jtagkBqS"
      },
      "source": [
        "from farm.utils import initialize_device_settings\n",
        "\n",
        "device, n_gpu = initialize_device_settings(use_cuda=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGtOVjMIBLtm"
      },
      "source": [
        "Load documents from repo, put in list of ditcts format, preprocess texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrqVdbAiuM0w",
        "outputId": "691eb063-886e-4a2f-ef0a-d0559ed63cad"
      },
      "source": [
        "#uplode Covid Repository Task 3.xlsx to files\n",
        "df = pd.read_excel('/content/Covid Repository Task 3.xlsx', header=1)\n",
        "df = df[['Title','Full_Text', 'URL']]\n",
        "\n",
        "\n",
        "dicts = []\n",
        "for index, row in df.iterrows():\n",
        "  dicts.append({'text':row['Full_Text'], \n",
        "                'meta':{'name':row['Title'], \n",
        "                        'URL':row['URL']\n",
        "                        }})\n",
        "preprocessor = PreProcessor(\n",
        "    clean_empty_lines=True,\n",
        "    clean_whitespace=True,\n",
        "    clean_header_footer=False,\n",
        "    split_by=\"sentence\",\n",
        "    split_length=7,\n",
        "    split_respect_sentence_boundary=False\n",
        ")\n",
        "\n",
        "nested_docs = [preprocessor.process(d) for d in dicts]\n",
        "docs = [d for x in nested_docs for d in x]\n",
        "\n",
        "print(f\"n_files_input: {len(dicts)}\\nn_docs_output: {len(docs)}\")  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "n_files_input: 101\n",
            "n_docs_output: 1994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62GMDe2T7KAf"
      },
      "source": [
        "Document store is the file system that the retriever uses to access the documents quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hxHTrAU9Up9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914b503d-7085-4d9b-da31-1bd88c445a47"
      },
      "source": [
        "from haystack.document_store.faiss import FAISSDocumentStore\n",
        "\n",
        "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\", similarity=\"dot_product\")\n",
        "document_store.write_documents(docs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sqlalchemy/orm/relationships.py:3463: SAWarning: relationship 'DocumentORM.Meta' will copy column document.id to column meta.document_id, which conflicts with relationship(s): 'MetaORM.Document' (copies document.id to meta.document_id), 'DocumentORM.meta' (copies document.id to meta.document_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   The 'overlaps' parameter may be used to remove this warning. (Background on this error at: http://sqlalche.me/e/14/qzyx)\n",
            "  code=\"qzyx\",\n",
            "/usr/local/lib/python3.7/dist-packages/sqlalchemy/orm/relationships.py:3463: SAWarning: relationship 'MetaORM.documents' will copy column document.id to column meta.document_id, which conflicts with relationship(s): 'MetaORM.Document' (copies document.id to meta.document_id), 'DocumentORM.meta' (copies document.id to meta.document_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   The 'overlaps' parameter may be used to remove this warning. (Background on this error at: http://sqlalche.me/e/14/qzyx)\n",
            "  code=\"qzyx\",\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kidwCCpADzZ9"
      },
      "source": [
        "Load the search models. The retriever finds the most relevant passages, while the reader extracts the answer from them. Or alternatively the retrieval augmented generator paraphrases the answer, trading explainability for quality. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDgtHU-1IMCZ"
      },
      "source": [
        "%%capture\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2-covid\", use_gpu=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrdloNMbe-QU"
      },
      "source": [
        "%%capture\n",
        "retriever = DensePassageRetriever(document_store=document_store,\n",
        "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
        "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
        "                                  max_seq_len_query=64,\n",
        "                                  max_seq_len_passage=256,\n",
        "                                  batch_size=16,\n",
        "                                  use_gpu=True,\n",
        "                                  embed_title=False,\n",
        "                                  use_fast_tokenizers=True)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJsfnL3jM4Ip"
      },
      "source": [
        "%%capture\n",
        "# Add documents embeddings to index\n",
        "document_store.update_embeddings(retriever=retriever)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5O2eZdRhTfe"
      },
      "source": [
        "# Format answer \n",
        "def print_answers(results: dict):\n",
        "  import pprint\n",
        "  pp = pprint.PrettyPrinter(indent=4)\n",
        "  answers = results[\"answers\"]\n",
        "\n",
        "  # filter the results\n",
        "  filtered_answers = []\n",
        "  for ans in answers:\n",
        "    filtered_answers.append({ 'score':ans['score'], 'URL':ans['meta']['URL'], 'paperName':ans['meta']['name'], 'answer':ans['answer']}) \n",
        "  #pp.pprint(filtered_answers)\n",
        "  return filtered_answers"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRQMRC3wDD3U"
      },
      "source": [
        "Run the pipeline, test with a query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud9qRC6TFyQa"
      },
      "source": [
        "%%capture\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)\n",
        "prediction = pipe.run(query=\"What are some economic repercussions from the covid-19 spread?\", top_k_retriever=50, top_k_reader=10)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUbL7GunuW52"
      },
      "source": [
        "# run this to\n",
        "filtered_answers = print_answers(prediction)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkhjKEqIkOiR"
      },
      "source": [
        "# export dummy for front end\n",
        "#import json\n",
        "#with open('predictions.json', 'w') as fout:\n",
        "#    json.dump(filtered_answers, fout)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQGHj9WRhnuw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2c3b9e-0cc4-4bf4-b066-da13219ec0d9"
      },
      "source": [
        "filtered_answers"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'URL': 'https://ps.psychiatryonline.org/doi/10.1176/appi.ps.202000393?url_ver=Z39.88-2003&rfr_id=ori%3Arid%3Acrossref.org&rfr_dat=cr_pub++0pubmed&',\n",
              "  'answer': 'A global economic slowdown has resulted from containment measures, accompanied by massive unemployment and fewer governmental resources to support public welfare systems. For each percentage point slowdown in the global economy, at least 14 million people are falling into poverty and food insecurity worldwide',\n",
              "  'paperName': 'Social Determinants of\\xa0Mental\\xa0Health\\xa0As Mediators and Moderators of the\\xa0Mental\\xa0Health\\xa0Impacts of the\\xa0COVID-19\\xa0Pandemic.',\n",
              "  'score': 8.75284194946289},\n",
              " {'URL': 'https://onlinelibrary.wiley.com/doi/10.1111/1746-692X.12288',\n",
              "  'answer': 'Harvesting may be disrupted because of a lack of workers; planting because of a lack of seed or fertiliser; transport because of reduced transport facilities; market exchange because of lockdowns or social distancing.',\n",
              "  'paperName': 'Covid‐19 and Global Food Security',\n",
              "  'score': 4.581579208374023},\n",
              " {'URL': 'https://eric.ed.gov/?q=covid+19+AND+(economy+OR+(economic+impact)+OR+(impact+on+economy)+OR+unemployment+OR+poverty)&id=EJ1273010',\n",
              "  'answer': 'Lack of funds have led to frustrated\\n- 86 -\\nhouseholds with increased child abuse, sexual abuse, increased screen time\\nfor children of all age group, lack of focus from education, fear of uncertain\\nfuture and acute depression',\n",
              "  'paperName': 'Traumatic Skepticism of COVID-19',\n",
              "  'score': 3.5648598670959473},\n",
              " {'URL': 'https://www.researchgate.net/profile/Ridho_Al_Izzati/publication/341151146_The_Impact_of_COVID-19_Outbreak_on_Poverty_An_Estimation_for_Indonesia/links/5eb1224a299bf18b9595b694/The-Impact-of-COVID-19-Outbreak-on-Poverty-An-Estimation-for-Indonesia.pdf',\n",
              "  'answer': 'recession. Along with  recessions, millions of people will become poor',\n",
              "  'paperName': 'The Impact of COVID-19 Outbreak on Poverty: An Estimation for Indonesia',\n",
              "  'score': 3.4807610511779785},\n",
              " {'URL': 'https://www.researchgate.net/profile/Mohamed_Buheji/publication/341044016_The_Extent_of_COVID-19_Pandemic_Socio-Economic_Impact_on_Global_Poverty_A_Global_Integrative_Multidisciplinary_Review/links/5eaab2f045851592d6ac3165/The-Extent-of-COVID-19-Pandemic-Socio-Economic-Impact-on-Global-Poverty-A-Global-Integrative-Multidisciplinary-Review.pdf',\n",
              "  'answer': 'famine, diseases, war, riots, etc.',\n",
              "  'paperName': 'The Extent of COVID-19 Pandemic Socio-Economic Impact on Global Poverty. A Global Integrative Multidisciplinary Review',\n",
              "  'score': 3.1408371925354004},\n",
              " {'URL': 'https://eric.ed.gov/?q=covid+19+AND+(economy+OR+(economic+impact)+OR+(impact+on+economy)+OR+unemployment+OR+poverty)&id=ED607423',\n",
              "  'answer': 'job losses or at best, shortened working hours in many sectors. Increased poverty and inequalities.',\n",
              "  'paperName': 'Mapping COVID-19: The Socio-Economic Impact. The Future of Skills in the EU Neighbourhood. Coping with COVID-19',\n",
              "  'score': 2.611386299133301},\n",
              " {'URL': 'https://ps.psychiatryonline.org/doi/10.1176/appi.ps.202000393?url_ver=Z39.88-2003&rfr_id=ori%3Arid%3Acrossref.org&rfr_dat=cr_pub++0pubmed&',\n",
              "  'answer': 'disadvantaged',\n",
              "  'paperName': 'Social Determinants of\\xa0Mental\\xa0Health\\xa0As Mediators and Moderators of the\\xa0Mental\\xa0Health\\xa0Impacts of the\\xa0COVID-19\\xa0Pandemic.',\n",
              "  'score': 1.4557688236236572},\n",
              " {'URL': 'https://journals.tubitak.gov.tr/medical/abstract.htm?id=27226',\n",
              "  'answer': 'since working parents\\nare more likely to miss work that leads to a wage loss\\nand adverse impact on production in the short term.',\n",
              "  'paperName': 'The early impact of the Covid-19 pandemic on the global and Turkish economy',\n",
              "  'score': 1.217003345489502},\n",
              " {'URL': 'http://www.rjef.ro/rjef/rjef2_20/rjef2_2020p5-17.pdf',\n",
              "  'answer': '14.6% and 12.6%',\n",
              "  'paperName': 'ESTIMATES OF DYNAMICS OF THE COVID19 PANDEMIC AND OF ITS IMPACT ON THE ECONOMY',\n",
              "  'score': 0.70147705078125},\n",
              " {'URL': 'https://onlinelibrary.wiley.com/doi/10.1002/pa.2206',\n",
              "  'answer': 'The prospects of the economy and the level of employment',\n",
              "  'paperName': 'Policy response to the economic challenge from COVID‐19 in India: A qualitative enquiry',\n",
              "  'score': 0.5915182828903198}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgYE6cGkD-9K"
      },
      "source": [
        "Now we test the system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVPIhlYM662a"
      },
      "source": [
        "# fresh document store\n",
        "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\", similarity=\"dot_product\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRTFASS1mVj4"
      },
      "source": [
        "#index names\n",
        "doc_index = \"evaluation_docs\"\n",
        "label_index = \"evaluation_labels\"\n",
        "\n",
        "# limited preprosessor capabilities for the evalutaion system\n",
        "preprocessor = PreProcessor(\n",
        "    clean_empty_lines=False,\n",
        "    clean_whitespace=False,\n",
        "    clean_header_footer=False,\n",
        "    split_by=\"word\",\n",
        "    split_length=500,\n",
        "    split_respect_sentence_boundary=False\n",
        ")\n",
        "\n",
        "document_store.delete_all_documents(index=doc_index)\n",
        "document_store.delete_all_documents(index=label_index)\n",
        "document_store.add_eval_data(\n",
        "    filename=\"/content/answers.json\",\n",
        "    doc_index=doc_index,\n",
        "    label_index=label_index,\n",
        "    preprocessor=preprocessor2,\n",
        "    open_domain=True\n",
        ")\n",
        "\n",
        "labels = document_store.get_all_labels_aggregated(index=label_index)\n",
        "q_to_l_dict = {\n",
        "    l.question: {\n",
        "        \"retriever\": l,\n",
        "        \"reader\": l\n",
        "    } for l in labels\n",
        "}\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x0JcM-g5qw6"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfc9kgliod39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c43886f-055c-4050-f901-1888acd86591"
      },
      "source": [
        "retriever = DensePassageRetriever(document_store=document_store,\n",
        "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
        "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
        "                                  max_seq_len_query=64,\n",
        "                                  max_seq_len_passage=256,\n",
        "                                  batch_size=16,\n",
        "                                  use_gpu=True,\n",
        "                                  embed_title=False,\n",
        "                                  use_fast_tokenizers=True)\n",
        "document_store.update_embeddings(retriever=retriever, index=doc_index)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/384 [00:00<?, ?it/s]\n",
            "Creating Embeddings:   0%|          | 0/24 [00:00<?, ? Batches/s]\u001b[A\n",
            "Creating Embeddings:   4%|▍         | 1/24 [00:14<05:22, 14.00s/ Batches]\u001b[A\n",
            "Creating Embeddings:   8%|▊         | 2/24 [00:28<05:08, 14.00s/ Batches]\u001b[A\n",
            "Creating Embeddings:  12%|█▎        | 3/24 [00:41<04:53, 13.97s/ Batches]\u001b[A\n",
            "Creating Embeddings:  17%|█▋        | 4/24 [00:55<04:39, 13.96s/ Batches]\u001b[A\n",
            "Creating Embeddings:  21%|██        | 5/24 [01:09<04:25, 13.96s/ Batches]\u001b[A\n",
            "Creating Embeddings:  25%|██▌       | 6/24 [01:23<04:10, 13.93s/ Batches]\u001b[A\n",
            "Creating Embeddings:  29%|██▉       | 7/24 [01:37<03:56, 13.90s/ Batches]\u001b[A\n",
            "Creating Embeddings:  33%|███▎      | 8/24 [01:51<03:42, 13.88s/ Batches]\u001b[A\n",
            "Creating Embeddings:  38%|███▊      | 9/24 [02:05<03:28, 13.91s/ Batches]\u001b[A\n",
            "Creating Embeddings:  42%|████▏     | 10/24 [02:19<03:14, 13.91s/ Batches]\u001b[A\n",
            "Creating Embeddings:  46%|████▌     | 11/24 [02:33<03:00, 13.88s/ Batches]\u001b[A\n",
            "Creating Embeddings:  50%|█████     | 12/24 [02:46<02:46, 13.89s/ Batches]\u001b[A\n",
            "Creating Embeddings:  54%|█████▍    | 13/24 [03:00<02:32, 13.88s/ Batches]\u001b[A\n",
            "Creating Embeddings:  58%|█████▊    | 14/24 [03:14<02:18, 13.84s/ Batches]\u001b[A\n",
            "Creating Embeddings:  62%|██████▎   | 15/24 [03:28<02:04, 13.83s/ Batches]\u001b[A\n",
            "Creating Embeddings:  67%|██████▋   | 16/24 [03:42<01:50, 13.83s/ Batches]\u001b[A\n",
            "Creating Embeddings:  71%|███████   | 17/24 [03:55<01:36, 13.82s/ Batches]\u001b[A\n",
            "Creating Embeddings:  75%|███████▌  | 18/24 [04:09<01:22, 13.79s/ Batches]\u001b[A\n",
            "Creating Embeddings:  79%|███████▉  | 19/24 [04:23<01:08, 13.79s/ Batches]\u001b[A\n",
            "Creating Embeddings:  83%|████████▎ | 20/24 [04:37<00:55, 13.79s/ Batches]\u001b[A\n",
            "Creating Embeddings:  88%|████████▊ | 21/24 [04:51<00:41, 13.80s/ Batches]\u001b[A\n",
            "Creating Embeddings:  92%|█████████▏| 22/24 [05:04<00:27, 13.74s/ Batches]\u001b[A\n",
            "Creating Embeddings:  96%|█████████▌| 23/24 [05:18<00:13, 13.69s/ Batches]\u001b[A\n",
            "Creating Embeddings: 100%|██████████| 24/24 [05:31<00:00, 13.83s/ Batches]\n",
            "10000it [05:33, 29.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjy3VF835zE6"
      },
      "source": [
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2-covid\", use_gpu=True, return_no_answer=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ0lGnjQtDkJ"
      },
      "source": [
        "#we import eval here, but the intantiations are used in the pipeline at last.\n",
        "from haystack.eval import EvalReader, EvalRetriever\n",
        "\n",
        "eval_retriever = EvalRetriever()\n",
        "eval_reader = EvalReader()\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7j6tLTzFC06"
      },
      "source": [
        "Only results from here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC-5Hw3Ptg0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f04895-b6b1-4064-96cf-698cc2806a1a"
      },
      "source": [
        "retriever_eval_results = retriever.eval(top_k=20, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
        "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
        "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 48/48 [00:14<00:00,  3.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Retriever Recall: 0.5625\n",
            "Retriever Mean Avg Precision: 0.21982135341510345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQc3dVBgmBRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9ddcc5-6048-46e9-dec2-8ce9e290de3b"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4OEXihOt4qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245a5084-06f1-4539-c505-0eec40c37e44"
      },
      "source": [
        "reader_eval_results = reader.eval(document_store=document_store, device=device,  label_index=label_index, doc_index=doc_index, top_k=10)\n",
        "\n",
        "print(\"Reader Top-N-Accuracy:\", reader_eval_results[\"top_n_accuracy\"])\n",
        "print(\"Reader Exact Match:\", reader_eval_results[\"EM\"])\n",
        "print(\"Reader F1-Score:\", reader_eval_results[\"f1\"])\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 5/5 [03:27<00:00, 41.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reader Top-N-Accuracy: 97.91666666666666\n",
            "Reader Exact Match: 2.083333333333333\n",
            "Reader F1-Score: 40.34146548652496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuf2Gw0iFP1Y"
      },
      "source": [
        "From here and down is impossible to do without GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2eF7LuHuIID"
      },
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "p = Pipeline()\n",
        "p.add_node(component=retriever, name=\"denseRetriever\", inputs=[\"Query\"])\n",
        "p.add_node(component=eval_retriever, name=\"EvalRetriever\", inputs=[\"denseRetriever\"])\n",
        "p.add_node(component=reader, name=\"QAReader\", inputs=[\"EvalRetriever\"])\n",
        "p.add_node(component=eval_reader, name=\"EvalReader\", inputs=[\"QAReader\"])\n",
        "results = []\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doeEFjf2uUc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "422c8440-b4bf-43d7-bc1f-d27679897858"
      },
      "source": [
        "%%capture\n",
        "for q, l in q_to_l_dict.items():\n",
        "    res = p.run(\n",
        "        query=q,\n",
        "        top_k_retriever=25,\n",
        "        labels=l,\n",
        "        top_k_reader=10,\n",
        "        index=doc_index,\n",
        "    )\n",
        "    results.append(res)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f3d10ddad5f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtop_k_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haystack/pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running node `{node_id}` with input `{node_input}`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                     \u001b[0mnode_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"component\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnode_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haystack/reader/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, documents, top_k_reader, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"query_time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k_reader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"answers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haystack/reader/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtoc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haystack/reader/farm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, query, documents, top_k)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# TODO: Need fix in FARM's `to_dict` function of `QAInput` class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         predictions = self.inferencer.inference_from_objects(\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mobjects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing_chunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# assemble answers from all the different documents & format them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/infer.py\u001b[0m in \u001b[0;36minference_from_objects\u001b[0;34m(self, objects, return_json, multiprocessing_chunksize, streaming)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;31m#logger.warning(\"QAInferencer.inference_from_objects() will soon be deprecated. Use QAInferencer.inference_from_dicts() instead\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         return self.inference_from_dicts(dicts, return_json=return_json,\n\u001b[0;32m--> 708\u001b[0;31m                                          multiprocessing_chunksize=multiprocessing_chunksize, streaming=streaming)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/infer.py\u001b[0m in \u001b[0;36minference_from_dicts\u001b[0;34m(self, dicts, return_json, multiprocessing_chunksize, streaming)\u001b[0m\n\u001b[1;32m    687\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'More than one question for document. NaturalQuestions inference will return just the answer to the first question.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         return Inferencer.inference_from_dicts(self, dicts, return_json=return_json,\n\u001b[0;32m--> 689\u001b[0;31m                                                multiprocessing_chunksize=multiprocessing_chunksize, streaming=streaming)\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     def inference_from_file(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/infer.py\u001b[0m in \u001b[0;36minference_from_dicts\u001b[0;34m(self, dicts, return_json, multiprocessing_chunksize, streaming)\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;31m# return a generator object if streaming is enabled, else, cast the generator to a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstreaming\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/infer.py\u001b[0m in \u001b[0;36m_inference_with_multiprocessing\u001b[0;34m(self, dicts, return_json, aggregate_preds, multiprocessing_chunksize)\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0maggregate_preds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                     predictions = self._get_predictions_and_aggregate(\n\u001b[0;32m--> 537\u001b[0;31m                         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaskets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m                     )\n\u001b[1;32m    539\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/infer.py\u001b[0m in \u001b[0;36m_get_predictions_and_aggregate\u001b[0;34m(self, dataset, tensor_names, baskets)\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;31m# Aggregation works on preds, not logits. We want as much processing happening in one batch + on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;31m# So we transform logits to preds here as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m                 \u001b[0;31m# preds = self.model.logits_to_preds(logits, **batch)[0] (This must somehow be useful for SQuAD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/modeling/adaptive_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Run forward pass of language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# Run forward pass of (multiple) prediction heads using the output from above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/modeling/adaptive_model.py\u001b[0m in \u001b[0;36mforward_lm\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# Run forward pass of language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextraction_layer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# get output from an earlier layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/modeling/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, segment_ids, padding_mask, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         )\n\u001b[1;32m    719\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 )\n\u001b[1;32m    452\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         )\n\u001b[1;32m    391\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo0dizWzurWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8042c44e-e328-4c54-f62d-d896248184cf"
      },
      "source": [
        "n_queries = len(labels)\n",
        "eval_retriever.print()\n",
        "print()\n",
        "retriever.print_time()\n",
        "print()\n",
        "eval_reader.print(mode=\"reader\")\n",
        "print()\n",
        "reader.print_time()\n",
        "print()\n",
        "eval_reader.print(mode=\"pipeline\")\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Retriever\n",
            "-----------------\n",
            "recall: 0.5897 (23 / 39)\n",
            "\n",
            "Retriever (Speed)\n",
            "---------------\n",
            "No indexing performed via Retriever.run()\n",
            "Queries Performed: 39\n",
            "Query time: 13.102201267000964s\n",
            "0.33595387864105036 seconds per query\n",
            "\n",
            "Reader\n",
            "-----------------\n",
            "has answer queries: 22\n",
            "top 1 EM: 0.0455\n",
            "top k EM: 0.0455\n",
            "top 1 F1: 0.3374\n",
            "top k F1: 0.4874\n",
            "\n",
            "Reader (Speed)\n",
            "---------------\n",
            "Queries Performed: 39\n",
            "Query time: 4784.799563666998s\n",
            "122.68716829915381 seconds per query\n",
            "\n",
            "Pipeline\n",
            "-----------------\n",
            "queries: 38\n",
            "top 1 EM: 0.0263\n",
            "top k EM: 0.0263\n",
            "top 1 F1: 0.1953\n",
            "top k F1: 0.2822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDb2l5Z_q4Q1"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}